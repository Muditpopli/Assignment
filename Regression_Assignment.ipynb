{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 1:\n",
        "\n",
        "Simple Linear Regression is a method used to find the relationship between two variables:\n",
        "\n",
        "One independent variable (X), and\n",
        "One dependent variable (Y).\n",
        "It tries to fit a straight line (called the regression line) through the data points in such a way that it predicts the value of Y based on the value of X.\n",
        "\n",
        "Example: If you want to predict someone's height (Y) based on their age (X), Simple Linear Regression can give you the formula for the best-fit line."
      ],
      "metadata": {
        "id": "HQrtKn76k9Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 2:\n",
        "\n",
        "For Simple Linear Regression to work properly, we make the following assumptions:\n",
        "\n",
        "Linearity: The relationship between X and Y is a straight line.\n",
        "Independence: The observations are independent of each other.\n",
        "Homoscedasticity: The variance of errors is constant for all values of X.\n",
        "Normality of Errors: The errors (differences between actual and predicted Y) follow a normal distribution.\n",
        "Example of Violations:\n",
        "\n",
        "If the data points curve (not a straight line), the linearity assumption is violated.\n",
        "If the spread of data points increases as X increases, homoscedasticity is violated."
      ],
      "metadata": {
        "id": "R6S0pyxtlACE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 3:\n",
        "\n",
        "The coefficient\n",
        "ğ‘š\n",
        "m is the slope of the line, which tells us how much Y changes for a one-unit change in X.\n",
        "\n",
        "Example: If\n",
        "ğ‘š\n",
        "=\n",
        "2\n",
        "m=2, it means that for every 1 unit increase in X, Y increases by 2 units. So, if X goes from 3 to 4, Y will increase by\n",
        "2\n",
        "Ã—\n",
        "1\n",
        "=\n",
        "2\n",
        "2Ã—1=2."
      ],
      "metadata": {
        "id": "7-bOoGQhqGfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 4:\n",
        "\n",
        "The intercept\n",
        "ğ‘\n",
        "c is the value of Y when X = 0. It tells us where the line crosses the Y-axis.\n",
        "\n",
        "Example: If\n",
        "ğ‘\n",
        "=\n",
        "5\n",
        "c=5, it means that when X is 0, Y is 5. So, the starting value of Y is 5 when thereâ€™s no contribution from X."
      ],
      "metadata": {
        "id": "bAWm_V6nqPEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 5:\n",
        "\n",
        "The slope\n",
        "ğ‘š\n",
        "m is calculated using this formula:\n",
        "\n",
        "ğ‘š\n",
        "=\n",
        "ğ‘›\n",
        "(\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        "ğ‘Œ\n",
        ")\n",
        "âˆ’\n",
        "(\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        ")\n",
        "(\n",
        "âˆ‘\n",
        "ğ‘Œ\n",
        ")\n",
        "ğ‘›\n",
        "(\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        "2\n",
        ")\n",
        "âˆ’\n",
        "(\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        ")\n",
        "2\n",
        "m=\n",
        "n(âˆ‘X\n",
        "2\n",
        " )âˆ’(âˆ‘X)\n",
        "2\n",
        "\n",
        "n(âˆ‘XY)âˆ’(âˆ‘X)(âˆ‘Y)\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘›\n",
        "n is the number of data points.\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        "ğ‘Œ\n",
        "âˆ‘XY is the sum of the products of X and Y.\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        "âˆ‘X and\n",
        "âˆ‘\n",
        "ğ‘Œ\n",
        "âˆ‘Y are the sums of X and Y values.\n",
        "âˆ‘\n",
        "ğ‘‹\n",
        "2\n",
        "âˆ‘X\n",
        "2\n",
        "  is the sum of squared X values.\n",
        "Simplified Explanation: It calculates how much Y changes for each unit increase in X by analyzing the overall trend in the data.\n",
        "\n",
        "Example: For two points (1, 2) and (2, 4):\n",
        "\n",
        "X: 1, 2\n",
        "Y: 2, 4\n",
        "ğ‘š\n",
        "=\n",
        "(\n",
        "2\n",
        ")\n",
        "(\n",
        "1\n",
        "âˆ—\n",
        "2\n",
        "+\n",
        "2\n",
        "âˆ—\n",
        "4\n",
        ")\n",
        "âˆ’\n",
        "(\n",
        "1\n",
        "+\n",
        "2\n",
        ")\n",
        "(\n",
        "2\n",
        "+\n",
        "4\n",
        ")\n",
        "(\n",
        "2\n",
        ")\n",
        "(\n",
        "1\n",
        "2\n",
        "+\n",
        "2\n",
        "2\n",
        ")\n",
        "âˆ’\n",
        "(\n",
        "1\n",
        "+\n",
        "2\n",
        ")\n",
        "2\n",
        "=\n",
        "2\n",
        "m=\n",
        "(2)(1\n",
        "2\n",
        " +2\n",
        "2\n",
        " )âˆ’(1+2)\n",
        "2\n",
        "\n",
        "(2)(1âˆ—2+2âˆ—4)âˆ’(1+2)(2+4)\n",
        "â€‹\n",
        " =2."
      ],
      "metadata": {
        "id": "44CJRm6OqVHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 6:\n",
        "\n",
        "The least squares method is used to find the best-fitting line in Simple Linear Regression. Its purpose is to minimize the sum of the squared differences (errors) between the actual Y values and the predicted Y values. This ensures that the line is as close as possible to all the data points.\n",
        "\n",
        "Example: If the actual Y value is 10 and the predicted Y value is 8, the error is 2. The squared error is\n",
        "2\n",
        "2\n",
        "=\n",
        "4\n",
        "2\n",
        "2\n",
        " =4."
      ],
      "metadata": {
        "id": "BbH6KDJfqbld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 7:\n",
        "\n",
        "The coefficient of determination,\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        " , measures the proportion of the variance in the dependent variable (Y) that is explained by the independent variable (X). It ranges from 0 to 1:\n",
        "\n",
        "ğ‘…\n",
        "2\n",
        "=\n",
        "0\n",
        "R\n",
        "2\n",
        " =0: The model explains none of the variability in Y.\n",
        "ğ‘…\n",
        "2\n",
        "=\n",
        "1\n",
        "R\n",
        "2\n",
        " =1: The model explains all the variability in Y.\n",
        "Example: An\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  value of 0.75 means that 75% of the variability in Y is explained by X."
      ],
      "metadata": {
        "id": "odXbl0sBqzgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 8:\n",
        "\n",
        "Multiple Linear Regression is an extension of Simple Linear Regression that uses two or more independent variables to predict the value of a dependent variable. The equation is:\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘š\n",
        "1\n",
        "ğ‘‹\n",
        "1\n",
        "+\n",
        "ğ‘š\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "â€¦\n",
        "+\n",
        "ğ‘\n",
        "Y=m\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " +m\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " +â€¦+c\n",
        "Example: Predicting house prices (Y) based on factors like size (Xâ‚), number of bedrooms (Xâ‚‚), and location (Xâ‚ƒ)."
      ],
      "metadata": {
        "id": "sYwK6R6_q5J3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 9:\n",
        "\n",
        "The main difference is:\n",
        "\n",
        "Simple Linear Regression: Involves one independent variable (X) and one dependent variable (Y).\n",
        "Multiple Linear Regression: Involves two or more independent variables (Xâ‚, Xâ‚‚, â€¦) and one dependent variable (Y).\n",
        "Example:\n",
        "\n",
        "Simple: Predicting weight (Y) based on height (X).\n",
        "Multiple: Predicting weight (Y) based on height (Xâ‚), age (Xâ‚‚), and gender (Xâ‚ƒ)."
      ],
      "metadata": {
        "id": "8Cg45w8-q9WC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 10:\n",
        "\n",
        "The key assumptions are:\n",
        "\n",
        "Linearity: The relationship between the dependent variable and each independent variable is linear.\n",
        "Independence: The observations are independent of each other.\n",
        "Homoscedasticity: The variance of errors is constant across all levels of the independent variables.\n",
        "Normality of Errors: The errors are normally distributed.\n",
        "No Multicollinearity: Independent variables should not be highly correlated with each other.\n",
        "Example of violation: If \"size of the house\" and \"number of bedrooms\" are highly correlated, multicollinearity exists, violating the last assumption."
      ],
      "metadata": {
        "id": "saXHH3nNrDV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 11:\n",
        "\n",
        "Heteroscedasticity occurs when the variance of errors is not constant across all levels of the independent variables. In other words, the spread of residuals (errors) changes as the value of the independent variable changes.\n",
        "\n",
        "Effects:\n",
        "\n",
        "It can lead to inefficient estimates of coefficients.\n",
        "It makes standard errors unreliable, which affects hypothesis testing and confidence intervals.\n",
        "Example: In a housing dataset, errors may increase as house size increases, leading to wider residuals for larger houses."
      ],
      "metadata": {
        "id": "IRIi1YFarJBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 12:\n",
        "\n",
        "Remove one of the correlated variables: Drop one of the highly correlated variables to reduce redundancy.\n",
        "Combine variables: Create a single variable by combining correlated variables (e.g., using their average or PCA).\n",
        "Regularization: Use Ridge or Lasso regression to penalize large coefficients and reduce the impact of multicollinearity.\n",
        "Variance Inflation Factor (VIF): Identify and remove variables with a high VIF score (>5 or 10).\n",
        "Standardize variables: Normalize variables to reduce scaling issues."
      ],
      "metadata": {
        "id": "tjhYVKkXsTlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 13:\n",
        "\n",
        "One-Hot Encoding: Converts each category into binary columns (e.g., \"Red\", \"Blue\", \"Green\" â†’ [1, 0, 0], [0, 1, 0], [0, 0, 1]).\n",
        "Label Encoding: Assigns a unique numeric value to each category (e.g., \"Red\" â†’ 1, \"Blue\" â†’ 2, \"Green\" â†’ 3).\n",
        "Dummy Encoding: Similar to one-hot encoding but drops one category to avoid multicollinearity.\n",
        "Frequency Encoding: Replaces categories with their frequency in the dataset.\n",
        "Target Encoding: Replaces categories with the mean of the target variable for that category.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nC3r7YhnsiE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 14:\n",
        "\n",
        "Interaction terms capture the combined effect of two or more independent variables on the dependent variable. They are used when the impact of one variable on the dependent variable depends on the value of another variable.\n",
        "\n",
        "Example: If you are predicting sales (Y) based on advertising spend (X1) and product price (X2), an interaction term (X1 * X2) can show how advertising's effect on sales changes with product price."
      ],
      "metadata": {
        "id": "aOi10nlzslSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 15:\n",
        "\n",
        "Simple Linear Regression: The intercept represents the value of the dependent variable (Y) when the independent variable (X) is 0.\n",
        "\n",
        "Multiple Linear Regression: The intercept represents the value of Y when all independent variables (Xâ‚, Xâ‚‚, â€¦) are 0. This interpretation may not always be meaningful if \"0\" is unrealistic for all variables (e.g., age and income both being 0)."
      ],
      "metadata": {
        "id": "suTgIKrwstSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 16:\n",
        "\n",
        "The slope represents the rate of change of the dependent variable (Y) with respect to the independent variable (X). It indicates how much Y changes for a one-unit increase in X.\n",
        "\n",
        "Positive slope: Y increases as X increases.\n",
        "Negative slope: Y decreases as X increases.\n",
        "Significance: The slope helps quantify the relationship between variables and is critical for making predictions.\n",
        "\n",
        "Example: If the slope is 3, it means that for every 1-unit increase in X, Y will increase by 3 units."
      ],
      "metadata": {
        "id": "twIkikWCtJuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 17:\n",
        "\n",
        "The intercept represents the value of the dependent variable (Y) when all independent variables (X) are 0. It provides a baseline or starting point for the relationship between the variables.\n",
        "\n",
        "Context: The intercept helps understand where the regression line crosses the Y-axis and gives insight into Y when thereâ€™s no contribution from X.\n",
        "Real-world significance: Its interpretation depends on whether \"X = 0\" makes sense in the given context. If not, the intercept may have limited practical meaning.\n",
        "Example: In predicting salary (Y) based on years of experience (X), the intercept could represent the expected salary for someone with 0 years of experience."
      ],
      "metadata": {
        "id": "d5L0MRiKtTIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 18:\n",
        "\n",
        "Ignores Overfitting: A high\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  value does not guarantee a good model; the model might overfit the data, especially with too many variables.\n",
        "\n",
        "Not Applicable to Nonlinear Models:\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  is designed for linear relationships and may not adequately assess nonlinear models.\n",
        "\n",
        "Does Not Indicate Causation: A high\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  only shows correlation, not causation between variables.\n",
        "\n",
        "Insensitive to Bias:\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  does not account for bias in predictions, which could make the model unreliable.\n",
        "\n",
        "Cannot Handle Multicollinearity: It doesnâ€™t detect issues like multicollinearity, which can make the model unstable.\n",
        "\n",
        "Fails for Out-of-Sample Performance:\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  measures performance on the training data but does not indicate how well the model will generalize to new data.\n",
        "\n",
        "Conclusion: While\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  is useful, it should be supplemented with other metrics like Adjusted\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        " , RMSE, or MAE, and techniques like cross-validation to assess model performance comprehensively."
      ],
      "metadata": {
        "id": "Fj3Xv1iktdMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 19:\n",
        "\n",
        "A large standard error for a regression coefficient indicates that there is high variability or uncertainty in the estimate of the coefficient. This suggests that the coefficient may not be reliably estimated, and small changes in the data could lead to significant differences in the coefficient value.\n",
        "\n",
        "Implications:\n",
        "\n",
        "The predictor (independent variable) may have a weak or inconsistent relationship with the dependent variable.\n",
        "There could be multicollinearity, where the predictor is highly correlated with other predictors.\n",
        "The sample size might be too small to produce stable estimates.\n",
        "Example: If the standard error for a coefficient is large, a hypothesis test (e.g.,\n",
        "ğ‘¡\n",
        "t-test) might show that the coefficient is not statistically significant, even if the coefficient value itself is large.\n",
        "\n",
        "Actionable Insight:\n",
        "\n",
        "Check for multicollinearity using Variance Inflation Factor (VIF).\n",
        "Increase the sample size or improve the model's design to reduce standard error."
      ],
      "metadata": {
        "id": "MPys0ZJKtw__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 20:\n",
        "\n",
        "Identifying Heteroscedasticity in Residual Plots:\n",
        "Residual Plot Observation:\n",
        "Plot residuals (errors) on the Y-axis against the predicted values or independent variables on the X-axis.\n",
        "If the spread of residuals increases or decreases as X increases (forming a funnel or cone shape), heteroscedasticity is present.\n",
        "Patterns: Look for non-random patterns in the residuals (e.g., increasing or decreasing variance).\n",
        "Example: A residual plot showing wider spread at higher predicted values indicates heteroscedasticity.\n",
        "\n",
        "Why is it Important to Address Heteroscedasticity?\n",
        "Biased Standard Errors: It leads to unreliable standard errors, making hypothesis tests (e.g.,\n",
        "ğ‘¡\n",
        "t-tests) invalid.\n",
        "Inefficient Coefficients: Although coefficients remain unbiased, they may not be the most precise estimates.\n",
        "Misleading Predictions: It can reduce the accuracy of the regression model, especially when applied to new data.\n",
        "How to Address:\n",
        "\n",
        "Use log transformation or other transformations of the dependent variable.\n",
        "Apply weighted least squares (WLS) to give less weight to observations with higher variance.\n",
        "Use robust standard errors to make hypothesis testing valid despite heteroscedasticity."
      ],
      "metadata": {
        "id": "cN6UgBHAt7Za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 21:\n",
        "\n",
        "This indicates that the model includes independent variables that do not significantly contribute to explaining the variation in the dependent variable. In other words, some variables in the model are irrelevant or redundant.\n",
        "\n",
        "Key Points:\n",
        "High\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        " : This suggests that the model explains a large proportion of the variance in the dependent variable.\n",
        "Low Adjusted\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        " : This penalizes the inclusion of unnecessary independent variables, indicating that some variables are not improving the model's performance.\n",
        "Implications:\n",
        "Adding irrelevant predictors inflates\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  artificially, as it always increases with more variables, regardless of their usefulness.\n",
        "Adjusted\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  corrects this by considering the number of predictors and their actual contribution.\n",
        "Example:\n",
        "If a model predicts house prices using variables like \"size\" and \"location\" (useful predictors) and includes an irrelevant variable like \"color of the walls,\"\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  may remain high, but Adjusted\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  will drop.\n",
        "\n",
        "Actionable Steps:\n",
        "Remove predictors that have low significance (e.g., using p-values or stepwise selection).\n",
        "Use Adjusted\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  for model evaluation rather than\n",
        "ğ‘…\n",
        "2\n",
        "R\n",
        "2\n",
        "  alone to avoid overfitting."
      ],
      "metadata": {
        "id": "C-Yak2owuL-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 22:\n",
        "\n",
        "Scaling variables ensures that all independent variables contribute equally to the model, especially when they have different units or ranges. Without scaling, variables with larger ranges can dominate the regression coefficients, leading to an imbalanced model.\n",
        "\n",
        "Key Reasons:\n",
        "Improves Interpretability:\n",
        "\n",
        "Scaling standardizes the range of variables, making the coefficients easier to compare and interpret.\n",
        "Prevents Numerical Instability:\n",
        "\n",
        "Large differences in variable scales can cause instability in the calculations, leading to inaccurate or unreliable results.\n",
        "Facilitates Convergence in Regularized Models:\n",
        "\n",
        "Techniques like Ridge and Lasso regression use penalties that are sensitive to variable magnitudes. Scaling ensures proper application of these penalties.\n",
        "Helps Handle Multicollinearity:\n",
        "\n",
        "Standardizing variables reduces the impact of high correlation between predictors with different scales.\n",
        "Example:\n",
        "If one variable is in meters (e.g., house size) and another in millions (e.g., house price), the regression model may assign disproportionately high weight to the larger-scaled variable, distorting the results.\n",
        "\n",
        "How to Scale:\n",
        "Standardization: Transform variables to have a mean of 0 and a standard deviation of 1.\n",
        "Normalization: Rescale variables to lie between 0 and 1.\n",
        "Scaling is particularly important in models where regularization or distance-based calculations (e.g., Ridge, Lasso, or PCA) are involved."
      ],
      "metadata": {
        "id": "MzTBCj5IuV2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 23:\n",
        "\n",
        "Polynomial Regression is a type of regression analysis where the relationship between the independent variable (X) and the dependent variable (Y) is modeled as a polynomial equation rather than a straight line. It extends linear regression by including higher-degree terms of the independent variable.\n",
        "\n",
        "Equation:\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "3\n",
        "ğ‘‹\n",
        "3\n",
        "+\n",
        "â€¦\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        " +b\n",
        "3\n",
        "â€‹\n",
        " X\n",
        "3\n",
        " +â€¦+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "\n",
        "Here:\n",
        "\n",
        "ğ‘\n",
        "0\n",
        ",\n",
        "ğ‘\n",
        "1\n",
        ",\n",
        "ğ‘\n",
        "2\n",
        ",\n",
        "â€¦\n",
        ",\n",
        "ğ‘\n",
        "ğ‘›\n",
        "b\n",
        "0\n",
        "â€‹\n",
        " ,b\n",
        "1\n",
        "â€‹\n",
        " ,b\n",
        "2\n",
        "â€‹\n",
        " ,â€¦,b\n",
        "n\n",
        "â€‹\n",
        "  are coefficients.\n",
        "ğ‘›\n",
        "n is the degree of the polynomial.\n",
        "When to Use Polynomial Regression?\n",
        "When the data shows a non-linear relationship that cannot be captured by a straight line.\n",
        "For example, U-shaped or S-shaped curves.\n",
        "Example:\n",
        "If you are predicting the growth of plants (Y) based on fertilizer amount (X), and the data suggests a curved pattern (e.g., growth increases up to a point and then declines), polynomial regression can model this trend better than linear regression."
      ],
      "metadata": {
        "id": "EVNxpC_Cum-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 24:\n",
        "\n",
        "Relationship Between Variables:\n",
        "\n",
        "Linear Regression: Models a straight-line relationship between the independent variable (X) and the dependent variable (Y).\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "Polynomial Regression: Models a non-linear relationship using polynomial terms of the independent variable (e.g.,\n",
        "ğ‘‹\n",
        "2\n",
        ",\n",
        "ğ‘‹\n",
        "3\n",
        "X\n",
        "2\n",
        " ,X\n",
        "3\n",
        " ).\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "â€¦\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        " +â€¦+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "\n",
        "Curve Fitting:\n",
        "\n",
        "Linear regression fits a straight line to the data.\n",
        "Polynomial regression fits a curved line to capture non-linear patterns.\n",
        "Complexity:\n",
        "\n",
        "Linear regression is simpler and interpretable.\n",
        "Polynomial regression is more flexible but can become overly complex if the degree of the polynomial is too high.\n",
        "Use Case:\n",
        "\n",
        "Linear regression works well when the relationship between X and Y is approximately linear.\n",
        "Polynomial regression is used when the relationship is non-linear but can be approximated by a polynomial function.\n",
        "Example:\n",
        "\n",
        "Linear Regression: Predicting income (Y) based on years of experience (X), assuming income increases linearly with experience.\n",
        "Polynomial Regression: Predicting the path of a ball thrown in the air (Y) based on time (X), where the path follows a parabolic curve (quadratic relationship).\n",
        "Key Consideration: While polynomial regression can handle non-linear data, overfitting can occur with higher-degree polynomials. Itâ€™s important to choose the degree of the polynomial carefully."
      ],
      "metadata": {
        "id": "5CVXgepSu8N3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 25:\n",
        "\n",
        "Polynomial regression is used when the relationship between the independent variable (X) and the dependent variable (Y) is non-linear but can be approximated using a polynomial function.\n",
        "\n",
        "Key Scenarios for Using Polynomial Regression:\n",
        "Non-Linear Relationships:\n",
        "\n",
        "When a simple straight-line model (linear regression) cannot capture the pattern in the data.\n",
        "Example: Modeling a U-shaped, S-shaped, or parabolic relationship.\n",
        "Curved Trends:\n",
        "\n",
        "When the dependent variable changes at varying rates with the independent variable.\n",
        "Example: Predicting house prices based on square footage, where smaller houses have a steeper price increase compared to larger ones.\n",
        "Physics or Natural Phenomena:\n",
        "\n",
        "Used in scenarios like projectile motion, growth curves, or temperature patterns.\n",
        "Example: Modeling the path of a ball thrown in the air (quadratic curve).\n",
        "Data with Turning Points:\n",
        "\n",
        "When the dependent variable increases, decreases, or fluctuates at certain intervals.\n",
        "Example: Modeling sales performance where sales first increase with advertising budget but decline beyond a certain point.\n",
        "Why Use Polynomial Regression?\n",
        "To model complex, curved relationships while maintaining the flexibility to adjust the degree of the polynomial for the best fit.\n",
        "Caution: Avoid using unnecessarily high degrees to prevent overfitting and poor generalization."
      ],
      "metadata": {
        "id": "wmpnwqE6vCnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 26:\n",
        "\n",
        "The general equation for polynomial regression is:\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "3\n",
        "ğ‘‹\n",
        "3\n",
        "+\n",
        "â€¦\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        " +b\n",
        "3\n",
        "â€‹\n",
        " X\n",
        "3\n",
        " +â€¦+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "\n",
        "Components:\n",
        "ğ‘Œ\n",
        "Y: Dependent variable (target to predict).\n",
        "ğ‘‹\n",
        "X: Independent variable (predictor).\n",
        "ğ‘\n",
        "0\n",
        "b\n",
        "0\n",
        "â€‹\n",
        " : Intercept (value of\n",
        "ğ‘Œ\n",
        "Y when\n",
        "ğ‘‹\n",
        "=\n",
        "0\n",
        "X=0).\n",
        "ğ‘\n",
        "1\n",
        ",\n",
        "ğ‘\n",
        "2\n",
        ",\n",
        "â€¦\n",
        ",\n",
        "ğ‘\n",
        "ğ‘›\n",
        "b\n",
        "1\n",
        "â€‹\n",
        " ,b\n",
        "2\n",
        "â€‹\n",
        " ,â€¦,b\n",
        "n\n",
        "â€‹\n",
        " : Coefficients for the polynomial terms.\n",
        "ğ‘‹\n",
        "2\n",
        ",\n",
        "ğ‘‹\n",
        "3\n",
        ",\n",
        "â€¦\n",
        ",\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "X\n",
        "2\n",
        " ,X\n",
        "3\n",
        " ,â€¦,X\n",
        "n\n",
        " : Higher-degree terms of the independent variable.\n",
        "Example:\n",
        "For a quadratic polynomial (degree 2):\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "\n",
        "For a cubic polynomial (degree 3):\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "3\n",
        "ğ‘‹\n",
        "3\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        " +b\n",
        "3\n",
        "â€‹\n",
        " X\n",
        "3\n",
        "\n",
        "Note: The degree of the polynomial (\n",
        "ğ‘›\n",
        "n) determines the flexibility of the curve. Higher degrees allow for more complex relationships but may lead to overfitting."
      ],
      "metadata": {
        "id": "jlVtntUYvVR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 27:\n",
        "\n",
        "Yes, polynomial regression can be applied to multiple variables. This involves creating polynomial terms not only for each individual independent variable but also for their interactions.\n",
        "\n",
        "General Equation:\n",
        "For two variables (\n",
        "ğ‘‹\n",
        "1\n",
        "X\n",
        "1\n",
        "â€‹\n",
        "  and\n",
        "ğ‘‹\n",
        "2\n",
        "X\n",
        "2\n",
        "â€‹\n",
        " ), the equation might look like:\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "1\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "3\n",
        "ğ‘‹\n",
        "1\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "4\n",
        "ğ‘‹\n",
        "2\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "5\n",
        "ğ‘‹\n",
        "1\n",
        "ğ‘‹\n",
        "2\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " +b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " +b\n",
        "3\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "2\n",
        "â€‹\n",
        " +b\n",
        "4\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "2\n",
        "â€‹\n",
        " +b\n",
        "5\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        "\n",
        "Here:\n",
        "\n",
        "ğ‘‹\n",
        "1\n",
        "2\n",
        "X\n",
        "1\n",
        "2\n",
        "â€‹\n",
        "  and\n",
        "ğ‘‹\n",
        "2\n",
        "2\n",
        "X\n",
        "2\n",
        "2\n",
        "â€‹\n",
        " : Squared terms (polynomials for individual variables).\n",
        "ğ‘‹\n",
        "1\n",
        "ğ‘‹\n",
        "2\n",
        "X\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " : Interaction term to capture combined effects.\n",
        "Steps for Applying Polynomial Regression with Multiple Variables:\n",
        "Include polynomial terms for each variable (e.g.,\n",
        "ğ‘‹\n",
        "1\n",
        "2\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "2\n",
        "X\n",
        "1\n",
        "2\n",
        "â€‹\n",
        " ,X\n",
        "2\n",
        "2\n",
        "â€‹\n",
        " ).\n",
        "Add interaction terms (e.g.,\n",
        "ğ‘‹\n",
        "1\n",
        "ğ‘‹\n",
        "2\n",
        "X\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " ).\n",
        "Fit the extended model using linear regression techniques.\n",
        "Example:\n",
        "Suppose you want to predict house prices (\n",
        "ğ‘Œ\n",
        "Y) based on size (\n",
        "ğ‘‹\n",
        "1\n",
        "X\n",
        "1\n",
        "â€‹\n",
        " ) and location score (\n",
        "ğ‘‹\n",
        "2\n",
        "X\n",
        "2\n",
        "â€‹\n",
        " ):\n",
        "\n",
        "A polynomial regression model might include terms like:\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "1\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "3\n",
        "ğ‘‹\n",
        "1\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "4\n",
        "ğ‘‹\n",
        "2\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "5\n",
        "ğ‘‹\n",
        "1\n",
        "ğ‘‹\n",
        "2\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " +b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " +b\n",
        "3\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "2\n",
        "â€‹\n",
        " +b\n",
        "4\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "2\n",
        "â€‹\n",
        " +b\n",
        "5\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        "\n",
        "This captures non-linear relationships between size and price, location and price, and their combined effect.\n",
        "\n",
        "Key Consideration:\n",
        "While polynomial regression with multiple variables can improve model accuracy, it may increase complexity and risk of overfitting, especially with high-degree polynomials or too many variables. Use techniques like cross-validation to evaluate model performance."
      ],
      "metadata": {
        "id": "nJeJjF3Evj3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 28:\n",
        "\n",
        "Risk of Overfitting:\n",
        "\n",
        "Higher-degree polynomials can fit the training data very closely, capturing noise instead of the underlying trend. This reduces the model's ability to generalize to new data.\n",
        "Complexity:\n",
        "\n",
        "As the degree of the polynomial increases, the equation becomes more complex and harder to interpret.\n",
        "Sensitivity to Outliers:\n",
        "\n",
        "Polynomial regression is highly sensitive to outliers, which can distort the curve and lead to poor predictions.\n",
        "Extrapolation Issues:\n",
        "\n",
        "Polynomial models are unreliable for predicting values outside the range of the training data (extrapolation), as they can produce extreme or unrealistic outputs.\n",
        "Multicollinearity:\n",
        "\n",
        "Adding higher-degree terms (e.g.,\n",
        "ğ‘‹\n",
        "2\n",
        ",\n",
        "ğ‘‹\n",
        "3\n",
        "X\n",
        "2\n",
        " ,X\n",
        "3\n",
        " ) can introduce multicollinearity, where predictors become highly correlated, making coefficient estimates unstable.\n",
        "Not Suitable for All Relationships:\n",
        "\n",
        "Polynomial regression assumes the relationship between variables can be expressed as a polynomial. It may fail to capture more complex relationships effectively.\n",
        "Computational Cost:\n",
        "\n",
        "With multiple variables and higher-degree terms, the model's computational cost increases significantly.\n",
        "Example of a Problem:\n",
        "A 10th-degree polynomial might fit training data perfectly but create a wavy, unrealistic curve that performs poorly on test data.\n",
        "Solution:\n",
        "To address these limitations:\n",
        "\n",
        "Use cross-validation to avoid overfitting.\n",
        "Regularize the model (e.g., Ridge or Lasso regression).\n",
        "Choose the polynomial degree carefully, balancing accuracy and complexity."
      ],
      "metadata": {
        "id": "_Oo4Xb1GvulQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 29:\n",
        "\n",
        "Visual Inspection:\n",
        "\n",
        "Plot the data and the fitted polynomial curve.\n",
        "Check if the curve captures the trend without overfitting (too wavy) or underfitting (too rigid).\n",
        "Mean Squared Error (MSE):\n",
        "\n",
        "Compute the average squared difference between predicted and actual values.\n",
        "Lower MSE indicates a better fit.\n",
        "Cross-Validation:\n",
        "\n",
        "Use techniques like k-fold cross-validation to evaluate model performance on unseen data and avoid overfitting.\n",
        "Compare the cross-validation error for different polynomial degrees.\n",
        "Adjusted RÂ²:\n",
        "\n",
        "Adjusted RÂ² accounts for the number of predictors in the model.\n",
        "Use it to compare models with different polynomial degrees. A higher adjusted RÂ² indicates a better fit without overfitting.\n",
        "Akaike Information Criterion (AIC) / Bayesian Information Criterion (BIC):\n",
        "\n",
        "These metrics penalize complex models.\n",
        "Lower AIC or BIC scores suggest a better balance between goodness of fit and model complexity.\n",
        "Residual Analysis:\n",
        "\n",
        "Plot residuals (differences between actual and predicted values) for different polynomial degrees.\n",
        "A good model will show residuals with no clear pattern (random scatter).\n",
        "Validation Set Approach:\n",
        "\n",
        "Split the data into training and validation sets.\n",
        "Train the model on the training set and evaluate its performance on the validation set for different polynomial degrees.\n",
        "Example:\n",
        "To determine the best degree of a polynomial for predicting sales based on advertising spend:\n",
        "\n",
        "Fit models with degrees 1, 2, 3, etc.\n",
        "Compare their performance using cross-validation error or adjusted RÂ².\n",
        "Select the degree where the model performs best without overfitting.\n",
        "By combining these methods, you can choose the optimal polynomial degree that balances accuracy and complexity."
      ],
      "metadata": {
        "id": "yXHSNRdLv6v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 30:\n",
        "\n",
        "Visualization plays a crucial role in polynomial regression because it helps to understand, analyze, and validate the modelâ€™s performance. Hereâ€™s why itâ€™s important:\n",
        "\n",
        "1. Understand the Fit of the Model:\n",
        "Visualizing the polynomial curve alongside the data points shows whether the model captures the underlying pattern.\n",
        "It helps identify if the model is underfitting (too rigid) or overfitting (too wavy).\n",
        "Example: A quadratic curve may fit data with a U-shaped trend, while a higher-degree polynomial might overfit and create unrealistic fluctuations.\n",
        "\n",
        "2. Detect Non-linear Patterns:\n",
        "Visualization makes it easier to identify non-linear relationships between the dependent and independent variables that may not be obvious from raw data.\n",
        "Example: A scatter plot with a fitted curve reveals whether the polynomial degree is appropriate for the data.\n",
        "\n",
        "3. Evaluate Residual Patterns:\n",
        "Plotting residuals (actual values - predicted values) helps check for randomness.\n",
        "Patterns in residuals suggest the model might be missing important relationships or using an inappropriate degree.\n",
        "4. Compare Models:\n",
        "Visualization allows comparison of polynomial models of different degrees to choose the one that best balances fit and complexity.\n",
        "5. Communicate Results:\n",
        "Visualizations make the results of polynomial regression easier to explain to stakeholders, especially non-technical audiences.\n",
        "Example:\n",
        "If youâ€™re modeling sales growth over time:\n",
        "\n",
        "A scatter plot of sales data with a fitted curve shows if the trend is captured correctly.\n",
        "Residual plots can highlight if higher-degree terms are necessary.\n",
        "Conclusion: Visualization helps ensure that the polynomial regression model is appropriate, interpretable, and effective in capturing the underlying relationship."
      ],
      "metadata": {
        "id": "zdbZsDA-wHJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to Q.No 31:"
      ],
      "metadata": {
        "id": "OrQO1LOQwRtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "KqnIzTV7wabg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating some non-linear data\n",
        "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)  # Independent variable\n",
        "y = np.array([3, 6, 10, 15, 25, 36, 50, 70, 95, 120])       # Dependent variable"
      ],
      "metadata": {
        "id": "6zWV_YKFwbC-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming input features to include polynomial terms\n",
        "degree = 2  # Change this to experiment with different degrees\n",
        "poly = PolynomialFeatures(degree=degree)\n",
        "X_poly = poly.fit_transform(X)  # Adds X^2, X^3, etc. terms"
      ],
      "metadata": {
        "id": "QxhWD-1owzYJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the polynomial regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_poly)"
      ],
      "metadata": {
        "id": "Zx23dsXvw2t5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncwxUHr5w5RK",
        "outputId": "fd5d02ab-cc22-43f0-8d5d-ac6d23b7ddb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 2.1253030303030354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the original data and the polynomial regression curve\n",
        "plt.scatter(X, y, color='blue', label='Original Data')  # Scatter plot of data points\n",
        "plt.plot(X, y_pred, color='red', label=f'Polynomial Degree {degree}')  # Fitted curve\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mCa6gjLUw70v",
        "outputId": "1f74d4f8-0e30-4a58-8767-c952318e49a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}